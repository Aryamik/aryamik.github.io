---
title: "Good Hearts Law"
#description: "blog post description (appears underneath the title in smaller text) which is included on the listing page"
author:
  - name: Aryamik Sharma
    url: https://aryamik.github.io
date: 06-28-2024
draft: true # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
editor: 
  markdown: 
    wrap: 72
bibliography: references.bib
---

::: {.callout-tip title="TL;DR"}
:::

I was listening to Episode #2156 of Joe Rogan Experience featuring
Jeremie & Edouard Harris from Gladstone AI, an organization dedicated to
promoting the responsible development and adoption of AI. The whole
episode had interesting tidbits that I really liked but for this post, I
wanted to focus on just segment - the economic principle of 'Goodhart's
Law'. They discuss it around 56:30:

```{=html}
<p align = 'center'><iframe width="560" height="315" src="https://youtu.be/c6JdeL90ans?t=3396" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></p>
```
> *This economic principle called Goodhart's Law where the minute you
> take a metric you were using to measure something. So you're saying, I
> don't know GDP is a great measure of how happy we are in the United
> States. Let's say it was. Sounds reasonable. The moment you turn that
> metric into a target that you're going to reward people for optimizing
> it stops measuring the thing it was measuring before. It stops being a
> good measure of the thing you cared about because people will come up
> with dangerously creative hacks, gaming the system, finding ways to
> make that number go up that don't map on to the intent that you had
> going in.*

This led me into a rabbit hole on what Goodhart's law is all about. It
can be traced back to 1975 when the British economist Charles Goodhart
expressed this idea in his article "Problems of Monetary Management: The
U.K. Experience". In the article Goodhart explains:

> *Any observed statistical regularity will tend to collapse once
> pressure is placed upon it for control purposes.*

Goodhart's Law was originally developed in the context of conducting
monetary policy on the basis of targets ([Goodhart
1984](https://conbio.onlinelibrary.wiley.com/doi/full/10.1111/j.1755-263X.2011.00167.x#b14)).
Ever since then, it has been restated as:

> *When a measure becomes a target, it ceases to be a good measure.*

It got me thinking about my own fitness journey. When I was just
starting out, I used to get so fixated on the number on weighing scale.
because in my head I rationalized it as:

*Lower weight = Being closer to my fitness goals.*

It got to a point where I became so obsessed with the number that I saw
on the weighing scale everyday that I started 'gaming' the system. I
started pulling off some shenanigans like being over zealous with my
cardio, being extremely restrictive with my calories so that the next
day the scale would read the number that I wanted to see. It got to a
point where I lost track of my broader fitness goals and why I was doing
it in the first place - to be more healthy and happy.

It wasn't until many years later that I realized the errors of my ways.
It occurred me to that weight is one of the many metrics that can be
used to gauge your progress. It can serve as a proxy for your fitness
journey but it is not the end all be all metric that is worth obsessing
over. Not only that, but relying solely on a weight loss scale for
fitness progress can turn misleading. These digital scales give weight
readings, but what's behind that number?

[Many variables affect your body
weight](https://rpstrength.com/blogs/articles/why-arent-your-results-good-enough),
such as:

-   Sleep

-   Carbohydrate intake

-   Sodium intake Fiber

-   Menstrual cycle

-   Food volume

-   Constipation

-   Stress

-   Hydration

Therefore even if you are giving 100%, the numbers on weighing scale can
fluctuate easily.

So what does this tell? Being obsessed with chasing a particular metric
(in this case the number on weighing scale) ends up telling nothing
about what we wanted to measure in the first place.

In Life 3.0 (which is easily one of my favorite books of all time), Max
Tegmark mentions that in our question to building Artificial General
Intelligence (AGI) as we get more intelligent and powerful machines, the
more important it will become becomes that their goals are aligned with
ours. He argues that figuring out how to align the goals of a
superintelligent AI with our goals isn't just important, but also hard
and continues to be an unsolved problem. For example if I ask a
self-driving car to take me to the airport as fast as possible and it
takes my word for it, the next thing I know I am being chased by
helicopters and I find myself covered in vomit. I could get mad at the
car all day long and tell it 'That's not what I wanted!', it can argue
'That's what you asked for.'

Let's take a look at another example of where Goodhart's law maybe
applicable - sustainability targets and initiatives.

Following the Paris Agreement, the [Intergovernmental Panel on Climate
Change](https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change "Intergovernmental Panel on Climate Change")
published its [Special Report on Global Warming of 1.5 °C
(SR15)](https://en.wikipedia.org/wiki/Special_Report_on_Global_Warming_of_1.5_%C2%B0C "Special Report on Global Warming of 1.5 °C")
in which stated that

> *"Reaching and sustaining net zero global anthropogenic
> \[human-caused\] CO~2~ emissions and declining net non-CO~2~[radiative
> forcing](https://en.wikipedia.org/wiki/Radiative_forcing "Radiative forcing")
> would halt anthropogenic global warming on multi-decadal timescales.*

Ever since then, there has been significant growth in the number of
actors pledging net zero emissions. Many standards such as the [Science
Based Targets
initiative](https://en.wikipedia.org/wiki/Science_Based_Targets_initiative "Science Based Targets initiative")
(SBTi) and International Sustainability Standards have emerged that
interpret the net zero concept and aim to measure progress towards net
zero targets.

The rise of these standards have led to the (re)emergence of various
policies and mechanisms such as carbon offsets.

The idea behind a carbon offset is that when an entity releases
greenhouse gases, they can pay someone else to remove an equivalent
amount of climate pollution from the atmosphere. For example, if an
automotive manufacturer in a developed country that wants to claim it is
reducing its emissions can pay for a patch of rainforest to be protected
in the Amazon that can absorb an equal amount of emissions. This in
theory -- cancels out - or offsets the impact of the automotive
manufacturer.

One can see the appeal for carbon offsets. For many industries, the cost
of addressing their own emissions can be a huge undertaking. By directly
funding offset projects, the cost of addressing climate change becomes
more manageable. It should work out, right?

The reality:

[![Source:
Bloomberg.com](images/Screenshot%20from%202024-06-29%2016-54-23.png){fig-align="center"}](https://www.bloomberg.com/news/articles/2023-08-24/junk-offsets-are-feeding-mass-wave-of-greenwashing-study-shows?sref=GBEdnt3o)

[![Source:
Time.com](images/Screenshot%20from%202024-06-29%2016-57-46.png)](https://time.com/6264772/study-most-carbon-credits-are-bogus/)

@west2023 analyzed 18 carbon-offset projects across Peru, Colombia,
Cambodia, Tanzania and the Democratic Republic of Congo and found that
only 5.4 million --- or 6% --- of a potential 89 million credits were
linked to additional carbon reductions through preserved forests.

Carbon offsets have been there since 1970s. So what went wrong?

Keeping aside the limitations of carbon offsets such as overstated
baselines, double counting of emissions, additionality; one can see how
Goodhart's law might be at play here.

Consider a simple example. A dairy farm wants to setup its operations in
California. This means the dairy farm will have to clear 1 hectare of
land to be up and running. Theoretically, the dairy farm could offset
its impact by planting 1 hectare of vegetation in Amazon. Soon enough,
this will prompt other dairy farms to do the same thing and before you
know it hundreds of acres of lands have been cleared in California. But
you might say : 'Aren't they making up for their impacts by offsetting
their emissions in Amazon?'

Partially yes. But 1 hectare of land in California is not the same as 1
hectare of land in Amazon. The ecological complexities of the two
regions are vastly different. This has been one of the criticisms of
carbon offsets where offset projects tend to become concentrated in the
developing countries.

The organizations can claim to be carbon neutral (which on paper they
might be). But in the end, are we really 'solving' for the underlying
problem?

Similarly, Goodhart's law finds it way in a related area - protecting
biodiversity.

Rapid declines in populations of various vulnerable species have led to
their inclusion in direct measures of biodiversity such as
[International Union for Conservation of Nature
(IUCN)](https://www.iucn.org/), Red List Index (RLI). The Index is based
on the IUCN Red List of Threatened Species™, which is widely considered
to be the leading assessment of the extinction risk of species. The Red
List involves the application of quantitative criteria based on
population size, distribution area, and rate of decline, to assign
species to different categories of relative extinction risk ([IUCN
2001](https://conbio.onlinelibrary.wiley.com/doi/full/10.1111/j.1755-263X.2011.00167.x#b19)).

As a result, a substantial research effort has been devoted to examining
the causes of decline in these vulnerable species. This has led to
increases in conservation efforts which have had some success in slowing
or even reversing the observed declines. At first glance, this can
viewed as a success story. However, it has also potentially undermined
the use of these species as a sustainability indicator. As policy and
management interventions have focused specifically on vulnerable
species, with the aim of improving this indicator, abundance of these
species is arguably now less representative of the general state of the
natural environment than it was hitherto. Consequently, any increase in
the indicator is more likely to be a measure of specific response
actions than of any general improvement in the state of the environment.

This post is not meant to be a criticism of carbon credits,
sustainability standards or indicators. Instead, it highlights how
despite our best efforts at measuring something, Goodhart law can find a
way to sneak in. So the obvious questions become:

Why does it happen?

What can we do about it?

In the JRE episode, Jeremie explains this happens because you end up
baking in some misalignment between what you want and what the system
wants. The more powerful that system becomes the the more it exploits
that gap. People will tend to affect any given indicator/measure in
whichever ways can be most readily achieved. As a result, indicators
become decoupled from underlying process that they are supposed to
indicate, and indicator values will become artificially inflated without
addressing the underlying problem.

How do we address this? I have been a huge proponent of 'What gets
measured, gets managed'. Do we get rid of measures altogether? No.

Before coming up with ways to quantify something, we should be really
clear with what do we want out of this action? Do I want to track my
daily weight or do I want to be the healthiest version of myself?

Do I want to offset my emissions or do I want to make sure the broader
environment is protected?

Being clear on what problem are we addressing from the get go should
help i

Once we are clear on that, then we should think of all the possible ways
in which the given indicator/measure could be exploited/gamified?
Specifically, systems should be put in place to prevent manipulation of
the indicators and the assessments on which they are based, to ensure
that the information they provide is objective and reliable. Use of
multiple indicator sets, including measures of pressure as well as state
variables, could help reduce scope for indicator manipulation.

Finally, there is a need for caution in interpreting the information
provided by any indicators that are used; at best, they can only provide
a partial indication of the status and trends of the process we are
trying to measure, and this needs to be appreciated by the
decision-makers who employ them.
